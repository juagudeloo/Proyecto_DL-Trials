Wed May 29 21:43:33 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.39       Driver Version: 460.39       CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce GTX TIT...  On   | 00000000:0A:00.0 Off |                  N/A |
| 22%   30C    P8    16W / 250W |     15MiB / 12212MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1848      G   /usr/bin/X                         13MiB |
+-----------------------------------------------------------------------------+
Soy un JOB GPU
Corri en la maquina: yaje.uis.edu.co
Corri el: Wed May 29 21:44:33 -05 2024

The model will be runned in: cuda

        ######################## 
        Reading 085000 MuRAM data...
        ######################## 
              
Charging temperature ...
Charging magnetic field vector...
Charging density...
Charge velocity...
Scaling...
Charging Stokes vectors...
Applying optical depth stratification...
(480, 20, 480, 4)
Scaling...
 STOKES:
        I_max = 4.253404982499902
        Q_max = 0.5017136567350976
        U_max = 0.50154366774811
        V_max = 0.07864951892765881
        I_min = 0.1904602250593744
        Q_min = 0.49862922934439674
        U_min = 0.4988378389159125
        V_min = -0.0780924820532529
        

        MAX VALUES:
        mtpr max = 1.7598589658737183
        mbxx max = 1.0264582633972168
        mbyy max = 1.2695895433425903
        mbzz max = 1.0088669061660767
        mrho max = 0.9729411602020264
        mvxx max = 1.0868189334869385
        mvyy max = 1.1035752296447754
        mvzz max = 1.1074299812316895
              

        MIN VALUES:
        mtpr min = 0.11763200908899307
        mbxx min = -0.12753601372241974
        mbyy min = -0.24923351407051086
        mbzz min = -0.049101319164037704
        mrho min = 1.6294233091684873e-06
        mvxx min = -0.08825806528329849
        mvyy min = -0.2050585001707077
        mvzz min = -0.09490993618965149
              

        ######################## 
        085000 MuRAM data charged...
        ######################## 
              
Separating in granular and intergranular...
leveraging...
Done
splitting...
Tensors stored in: cuda

    Shape of the data
            tr_input shape =torch.Size([140618, 4, 300])
            test_input shape = torch.Size([69260, 4, 300])
            tr_output shape = torch.Size([140618, 80])
            test_output shape = torch.Size([69260, 80])
            
Length of train dataloader: 1758 batches of 80
Length of test dataloader: 866 batches of 80

    Shape of each batch input and output:
    train input batch shape: torch.Size([80, 4, 300]), 
    train output batch shape: torch.Size([80, 80])
            
Epoch: 0
-------
Looked at 0/140618 samples
Looked at 32000/140618 samples
Looked at 64000/140618 samples
Looked at 96000/140618 samples
Looked at 128000/140618 samples

Train loss: 0.00397 | Test loss: 0.00197, Test acc: 89.82%

Epoch: 1
-------
Looked at 0/140618 samples
Looked at 32000/140618 samples
Looked at 64000/140618 samples
Looked at 96000/140618 samples
Looked at 128000/140618 samples

Train loss: 0.00214 | Test loss: 0.00200, Test acc: 89.82%

Epoch: 2
-------
Looked at 0/140618 samples
Looked at 32000/140618 samples
Looked at 64000/140618 samples
Looked at 96000/140618 samples
Looked at 128000/140618 samples

Train loss: 0.00206 | Test loss: 0.00192, Test acc: 89.82%

Epoch: 3
-------
Looked at 0/140618 samples
Looked at 32000/140618 samples
Looked at 64000/140618 samples
Looked at 96000/140618 samples
Looked at 128000/140618 samples

Train loss: 0.00200 | Test loss: 0.00181, Test acc: 89.82%

Epoch: 4
-------
Looked at 0/140618 samples
Looked at 32000/140618 samples
Looked at 64000/140618 samples
Looked at 96000/140618 samples
Looked at 128000/140618 samples

Train loss: 0.00198 | Test loss: 0.00180, Test acc: 89.82%

Epoch: 5
-------
Looked at 0/140618 samples
Looked at 32000/140618 samples
Looked at 64000/140618 samples
Looked at 96000/140618 samples
Looked at 128000/140618 samples

Train loss: 0.00195 | Test loss: 0.00187, Test acc: 89.82%

Epoch: 6
-------
Looked at 0/140618 samples
Looked at 32000/140618 samples
Looked at 64000/140618 samples
Looked at 96000/140618 samples
Looked at 128000/140618 samples

Train loss: 0.00192 | Test loss: 0.00175, Test acc: 89.82%

Epoch: 7
-------
Looked at 0/140618 samples
Looked at 32000/140618 samples
Looked at 64000/140618 samples
Looked at 96000/140618 samples
Looked at 128000/140618 samples

Train loss: 0.00189 | Test loss: 0.00171, Test acc: 89.82%

Epoch: 8
-------
Looked at 0/140618 samples
Looked at 32000/140618 samples
Looked at 64000/140618 samples
Looked at 96000/140618 samples
Looked at 128000/140618 samples

Train loss: 0.00186 | Test loss: 0.00177, Test acc: 89.82%

Epoch: 9
-------
Looked at 0/140618 samples
Looked at 32000/140618 samples
Looked at 64000/140618 samples
Looked at 96000/140618 samples
Looked at 128000/140618 samples

Train loss: 0.00184 | Test loss: 0.00175, Test acc: 89.82%

Train time on cuda:0: 2848.991 seconds
Saving model to: Results/model_weights/inversion_10E_0.001lr.pth

        ######################## 
        Reading 090000 MuRAM data...
        ######################## 
              
Charging temperature ...
Charging magnetic field vector...
Charging density...
Charge velocity...
Scaling...
Charging Stokes vectors...
Applying optical depth stratification...
(480, 20, 480, 4)
Scaling...
 STOKES:
        I_max = 4.020107690160626
        Q_max = 0.5050571652833595
        U_max = 0.508974781626016
        V_max = 0.14711644327283524
        I_min = 0.18727625249494514
        Q_min = 0.4935980221935864
        U_min = 0.49382378646832664
        V_min = -0.15434286867004676
        

        MAX VALUES:
        mtpr max = 1.7623074054718018
        mbxx max = 1.2131125926971436
        mbyy max = 1.6065375804901123
        mbzz max = 1.537561297416687
        mrho max = 0.9780371785163879
        mvxx max = 1.0713227987289429
        mvyy max = 1.0057792663574219
        mvzz max = 1.0488107204437256
              

        MIN VALUES:
        mtpr min = 0.17562896013259888
        mbxx min = -0.2861877381801605
        mbyy min = -0.5834845900535583
        mbzz min = -0.4514210820198059
        mrho min = 1.7066988675651373e-06
        mvxx min = -0.06825975328683853
        mvyy min = -0.1901446282863617
        mvzz min = -0.031931813806295395
              

        ######################## 
        090000 MuRAM data charged...
        ######################## 
              
Separating in granular and intergranular...
leveraging...
Done
splitting...
Tensors stored in: cuda

    Shape of the data
            tr_input shape =torch.Size([143712, 4, 300])
            test_input shape = torch.Size([70784, 4, 300])
            tr_output shape = torch.Size([143712, 80])
            test_output shape = torch.Size([70784, 80])
            
Length of train dataloader: 1797 batches of 80
Length of test dataloader: 885 batches of 80

    Shape of each batch input and output:
    train input batch shape: torch.Size([80, 4, 300]), 
    train output batch shape: torch.Size([80, 80])
            
Epoch: 0
-------
Looked at 0/143712 samples
Looked at 32000/143712 samples
Looked at 64000/143712 samples
Looked at 96000/143712 samples
Looked at 128000/143712 samples

Train loss: 0.00180 | Test loss: 0.00164, Test acc: 89.81%

Epoch: 1
-------
Looked at 0/143712 samples
Looked at 32000/143712 samples
Looked at 64000/143712 samples
Looked at 96000/143712 samples
Looked at 128000/143712 samples

Train loss: 0.00176 | Test loss: 0.00171, Test acc: 89.81%

Epoch: 2
-------
Looked at 0/143712 samples
Looked at 32000/143712 samples
Looked at 64000/143712 samples
Looked at 96000/143712 samples
Looked at 128000/143712 samples

Train loss: 0.00175 | Test loss: 0.00163, Test acc: 89.81%

Epoch: 3
-------
Looked at 0/143712 samples
Looked at 32000/143712 samples
Looked at 64000/143712 samples
Looked at 96000/143712 samples
Looked at 128000/143712 samples

Train loss: 0.00173 | Test loss: 0.00159, Test acc: 89.56%

Epoch: 4
-------
Looked at 0/143712 samples
Looked at 32000/143712 samples
Looked at 64000/143712 samples
Looked at 96000/143712 samples
Looked at 128000/143712 samples

Train loss: 0.00172 | Test loss: 0.00162, Test acc: 89.80%

Epoch: 5
-------
Looked at 0/143712 samples
Looked at 32000/143712 samples
Looked at 64000/143712 samples
Looked at 96000/143712 samples
Looked at 128000/143712 samples

Train loss: 0.00171 | Test loss: 0.00159, Test acc: 89.17%

Epoch: 6
-------
Looked at 0/143712 samples
Looked at 32000/143712 samples
Looked at 64000/143712 samples
Looked at 96000/143712 samples
Looked at 128000/143712 samples

Train loss: 0.00170 | Test loss: 0.00158, Test acc: 89.80%

Epoch: 7
-------
Looked at 0/143712 samples
Looked at 32000/143712 samples
Looked at 64000/143712 samples
Looked at 96000/143712 samples
Looked at 128000/143712 samples

Train loss: 0.00170 | Test loss: 0.00162, Test acc: 89.80%

Epoch: 8
-------
Looked at 0/143712 samples
Looked at 32000/143712 samples
Looked at 64000/143712 samples
Looked at 96000/143712 samples
Looked at 128000/143712 samples

Train loss: 0.00169 | Test loss: 0.00158, Test acc: 89.80%

Epoch: 9
-------
Looked at 0/143712 samples
Looked at 32000/143712 samples
Looked at 64000/143712 samples
Looked at 96000/143712 samples
Looked at 128000/143712 samples

Train loss: 0.00168 | Test loss: 0.00154, Test acc: 89.80%

Train time on cuda:0: 5765.672 seconds
Saving model to: Results/model_weights/inversion_10E_0.001lr.pth

        ######################## 
        Reading 095000 MuRAM data...
        ######################## 
              
Charging temperature ...
Charging magnetic field vector...
Charging density...
Charge velocity...
Scaling...
Charging Stokes vectors...
Applying optical depth stratification...
(480, 20, 480, 4)
Scaling...
 STOKES:
        I_max = 4.035907422207875
        Q_max = 0.5068776836553925
        U_max = 0.5085627737129531
        V_max = 0.18255802533678633
        I_min = 0.20187107991788808
        Q_min = 0.4800770399640187
        U_min = 0.49131280979791286
        V_min = -0.1435467005520961
        

        MAX VALUES:
        mtpr max = 1.75748610496521
        mbxx max = 1.5044220685958862
        mbyy max = 2.2299654483795166
        mbzz max = 1.8007941246032715
        mrho max = 0.9624638557434082
        mvxx max = 1.0423277616500854
        mvyy max = 0.935822069644928
        mvzz max = 1.065813422203064
              

        MIN VALUES:
        mtpr min = 0.16730833053588867
        mbxx min = -0.959823727607727
        mbyy min = -0.7560527324676514
        mbzz min = -0.8495694398880005
        mrho min = 2.5635911242716247e-06
        mvxx min = -0.07075606286525726
        mvyy min = -0.21803975105285645
        mvzz min = -0.046188563108444214
              

        ######################## 
        095000 MuRAM data charged...
        ######################## 
              
Separating in granular and intergranular...
leveraging...
Done
splitting...
Tensors stored in: cuda

    Shape of the data
            tr_input shape =torch.Size([133571, 4, 300])
            test_input shape = torch.Size([65789, 4, 300])
            tr_output shape = torch.Size([133571, 80])
            test_output shape = torch.Size([65789, 80])
            
Length of train dataloader: 1670 batches of 80
Length of test dataloader: 823 batches of 80

    Shape of each batch input and output:
    train input batch shape: torch.Size([80, 4, 300]), 
    train output batch shape: torch.Size([80, 80])
            
Epoch: 0
-------
Looked at 0/133571 samples
Looked at 32000/133571 samples
Looked at 64000/133571 samples
Looked at 96000/133571 samples
Looked at 128000/133571 samples

Train loss: 0.00182 | Test loss: 0.00174, Test acc: 89.68%

Epoch: 1
-------
Looked at 0/133571 samples
Looked at 32000/133571 samples
Looked at 64000/133571 samples
Looked at 96000/133571 samples
Looked at 128000/133571 samples

Train loss: 0.00178 | Test loss: 0.00170, Test acc: 89.66%

Epoch: 2
-------
Looked at 0/133571 samples
Looked at 32000/133571 samples
Looked at 64000/133571 samples
Looked at 96000/133571 samples
Looked at 128000/133571 samples

Train loss: 0.00177 | Test loss: 0.00171, Test acc: 89.68%

Epoch: 3
-------
Looked at 0/133571 samples
Looked at 32000/133571 samples
Looked at 64000/133571 samples
Looked at 96000/133571 samples
Looked at 128000/133571 samples

Train loss: 0.00176 | Test loss: 0.00163, Test acc: 89.61%

Epoch: 4
-------
Looked at 0/133571 samples
Looked at 32000/133571 samples
Looked at 64000/133571 samples
Looked at 96000/133571 samples
Looked at 128000/133571 samples

Train loss: 0.00174 | Test loss: 0.00165, Test acc: 89.67%

Epoch: 5
-------
Looked at 0/133571 samples
Looked at 32000/133571 samples
Looked at 64000/133571 samples
Looked at 96000/133571 samples
Looked at 128000/133571 samples

Train loss: 0.00173 | Test loss: 0.00162, Test acc: 89.69%

Epoch: 6
-------
Looked at 0/133571 samples
Looked at 32000/133571 samples
Looked at 64000/133571 samples
Looked at 96000/133571 samples
Looked at 128000/133571 samples

Train loss: 0.00173 | Test loss: 0.00162, Test acc: 89.69%

Epoch: 7
-------
Looked at 0/133571 samples
Looked at 32000/133571 samples
Looked at 64000/133571 samples
Looked at 96000/133571 samples
Looked at 128000/133571 samples

Train loss: 0.00172 | Test loss: 0.00166, Test acc: 89.68%

Epoch: 8
-------
Looked at 0/133571 samples
Looked at 32000/133571 samples
Looked at 64000/133571 samples
Looked at 96000/133571 samples
Looked at 128000/133571 samples

Train loss: 0.00171 | Test loss: 0.00167, Test acc: 89.68%

Epoch: 9
-------
Looked at 0/133571 samples
Looked at 32000/133571 samples
Looked at 64000/133571 samples
Looked at 96000/133571 samples
Looked at 128000/133571 samples

Train loss: 0.00171 | Test loss: 0.00165, Test acc: 89.70%

Train time on cuda:0: 8481.716 seconds
Saving model to: Results/model_weights/inversion_10E_0.001lr.pth
