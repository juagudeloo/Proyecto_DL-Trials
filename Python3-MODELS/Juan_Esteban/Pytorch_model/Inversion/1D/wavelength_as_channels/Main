class InvModel1(nn.Module):
    def __init__(self, in_shape, out_shape, hidden_units):
        super().__init__()
        padding = 1
        self.simple_conv = nn.Sequential(nn.Conv1d(in_channels=in_shape, out_channels=600, kernel_size = 2, stride=1, padding=padding),
        nn.ReLU(),
        nn.Conv1d(in_channels=600, out_channels=1200, kernel_size = 2, stride=1, padding=padding),
        nn.ReLU(),
        nn.Conv1d(in_channels=1200, out_channels=2400, kernel_size = 2, stride=1, padding=padding),
        nn.ReLU(),
        nn.Conv1d(in_channels=2400, out_channels=4800, kernel_size = 2, stride=1, padding=padding),
        nn.ReLU(),
        nn.Flatten(),
        nn.Dropout(p=0.5, inplace=False),
        nn.Linear(in_features = 38400, out_features = out_shape))
    def forward(self, x):
        return self.simple_conv(x)
#Creating the model for training
    model_0 = InvModel1(300,4*20,4096).float()
    #Defining the agnostic device
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print("\nThe model will be runned in:", device)
    #Model training hyperparams
    model_0.to(device)
    loss_fn = nn.MSELoss() # this is also called "criterion"/"cost function" in some places
    lr = 1e-4
    optimizer = torch.optim.Adam(params=model_0.parameters(), lr=lr)
    epochs = 1
    